{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "dab736a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ddbe52b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5b5a2467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "15b5fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['id','Unnamed: 32'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "92679f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8d8a2c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c9a674c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X=df.iloc[: ,1:]\n",
    "Y=df.iloc[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d94a56ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "16fea4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "label=LabelEncoder()\n",
    "y_train=label.fit_transform(y_train)\n",
    "y_test=label.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0c3f93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor=torch.tensor(X_train)\n",
    "X_test_tensor=torch.tensor(X_test)\n",
    "y_train_tensor=torch.tensor(y_train)\n",
    "y_test_tensor=torch.tensor(y_test)\n",
    "X_train_tensor = X_train_tensor.to(torch.float32)\n",
    "y_train_tensor = y_train_tensor.to(torch.float32)\n",
    "X_test_tensor = X_test_tensor.to(torch.float32)\n",
    "y_test_tensor = y_test_tensor.to(torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1ad59a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self,features,labels):\n",
    "        self.features=features\n",
    "        self.labels=labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.features[idx],self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7f86f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=CustomDataset(X_train_tensor,y_train_tensor)\n",
    "test_dataset=CustomDataset(X_test_tensor,y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1f108dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.5465, -1.3707, -0.5279, -0.5641,  0.7430, -0.1793, -0.7572, -0.5307,\n",
       "          0.2215,  0.2670, -0.7158, -0.7411, -0.4376, -0.5323, -0.1142, -0.0555,\n",
       "         -0.6930, -0.6012,  0.6378,  0.1277, -0.5953, -1.2702, -0.4665, -0.5808,\n",
       "          0.4652,  0.0314, -0.8210, -0.4974,  0.8761,  0.4630]),\n",
       " tensor(0.))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a9ac0b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader =DataLoader(train_dataset, batch_size=32,shuffle=True)\n",
    "test_loader =DataLoader(test_dataset, batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0bae7c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self,num_features):\n",
    "        super().__init__()\n",
    "        self.network=nn.Sequential(\n",
    "            nn.Linear(num_features,15),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(15,5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5,3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self,features):\n",
    "        out=self.network(features)\n",
    "        return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0ea711b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.1\n",
    "epochs=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "436c9d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func=nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ccd9ed2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 , loss:0.7512751221656799\n",
      "Epoch:1 , loss:0.694809079170227\n",
      "Epoch:1 , loss:0.7314677834510803\n",
      "Epoch:1 , loss:0.7504082918167114\n",
      "Epoch:1 , loss:0.7677391767501831\n",
      "Epoch:1 , loss:0.7392725944519043\n",
      "Epoch:1 , loss:0.7184621691703796\n",
      "Epoch:1 , loss:0.7479846477508545\n",
      "Epoch:1 , loss:0.7224974632263184\n",
      "Epoch:1 , loss:0.7071040868759155\n",
      "Epoch:1 , loss:0.7281863689422607\n",
      "Epoch:1 , loss:0.7323960065841675\n",
      "Epoch:1 , loss:0.7156693339347839\n",
      "Epoch:2 , loss:0.7014817595481873\n",
      "Epoch:2 , loss:0.700435996055603\n",
      "Epoch:2 , loss:0.6979866027832031\n",
      "Epoch:2 , loss:0.6820181608200073\n",
      "Epoch:2 , loss:0.6848375797271729\n",
      "Epoch:2 , loss:0.6985023021697998\n",
      "Epoch:2 , loss:0.6805312037467957\n",
      "Epoch:2 , loss:0.6831246614456177\n",
      "Epoch:2 , loss:0.6798282265663147\n",
      "Epoch:2 , loss:0.6736394762992859\n",
      "Epoch:2 , loss:0.673721194267273\n",
      "Epoch:2 , loss:0.6713276505470276\n",
      "Epoch:2 , loss:0.6668168306350708\n",
      "Epoch:3 , loss:0.6525135040283203\n",
      "Epoch:3 , loss:0.6601929664611816\n",
      "Epoch:3 , loss:0.6418851613998413\n",
      "Epoch:3 , loss:0.6535371541976929\n",
      "Epoch:3 , loss:0.6520408987998962\n",
      "Epoch:3 , loss:0.657584547996521\n",
      "Epoch:3 , loss:0.6556221842765808\n",
      "Epoch:3 , loss:0.6517930030822754\n",
      "Epoch:3 , loss:0.6318422555923462\n",
      "Epoch:3 , loss:0.6725895404815674\n",
      "Epoch:3 , loss:0.6163667440414429\n",
      "Epoch:3 , loss:0.676095724105835\n",
      "Epoch:3 , loss:0.6545937657356262\n",
      "Epoch:4 , loss:0.6478586196899414\n",
      "Epoch:4 , loss:0.6728561520576477\n",
      "Epoch:4 , loss:0.6446700692176819\n",
      "Epoch:4 , loss:0.6482341289520264\n",
      "Epoch:4 , loss:0.6002908945083618\n",
      "Epoch:4 , loss:0.6221255660057068\n",
      "Epoch:4 , loss:0.5986129641532898\n",
      "Epoch:4 , loss:0.6126236915588379\n",
      "Epoch:4 , loss:0.6084746718406677\n",
      "Epoch:4 , loss:0.6115719676017761\n",
      "Epoch:4 , loss:0.6091669201850891\n",
      "Epoch:4 , loss:0.5963390469551086\n",
      "Epoch:4 , loss:0.534917950630188\n",
      "Epoch:5 , loss:0.6273822784423828\n",
      "Epoch:5 , loss:0.609426736831665\n",
      "Epoch:5 , loss:0.5891112089157104\n",
      "Epoch:5 , loss:0.5740518569946289\n",
      "Epoch:5 , loss:0.5921547412872314\n",
      "Epoch:5 , loss:0.6121314167976379\n",
      "Epoch:5 , loss:0.6240994930267334\n",
      "Epoch:5 , loss:0.5451720356941223\n",
      "Epoch:5 , loss:0.5379215478897095\n",
      "Epoch:5 , loss:0.5198277235031128\n",
      "Epoch:5 , loss:0.5704784393310547\n",
      "Epoch:5 , loss:0.5604963302612305\n",
      "Epoch:5 , loss:0.5485610365867615\n",
      "Epoch:6 , loss:0.5986587405204773\n",
      "Epoch:6 , loss:0.5944733619689941\n",
      "Epoch:6 , loss:0.5364049077033997\n",
      "Epoch:6 , loss:0.5200554728507996\n",
      "Epoch:6 , loss:0.4519401490688324\n",
      "Epoch:6 , loss:0.5059190392494202\n",
      "Epoch:6 , loss:0.5306811928749084\n",
      "Epoch:6 , loss:0.5035158395767212\n",
      "Epoch:6 , loss:0.5709170699119568\n",
      "Epoch:6 , loss:0.5383601784706116\n",
      "Epoch:6 , loss:0.46813100576400757\n",
      "Epoch:6 , loss:0.5019739270210266\n",
      "Epoch:6 , loss:0.5029601454734802\n",
      "Epoch:7 , loss:0.4983277916908264\n",
      "Epoch:7 , loss:0.4966997802257538\n",
      "Epoch:7 , loss:0.37996575236320496\n",
      "Epoch:7 , loss:0.5220680236816406\n",
      "Epoch:7 , loss:0.40848541259765625\n",
      "Epoch:7 , loss:0.4688108265399933\n",
      "Epoch:7 , loss:0.4312267601490021\n",
      "Epoch:7 , loss:0.5346617698669434\n",
      "Epoch:7 , loss:0.5446584224700928\n",
      "Epoch:7 , loss:0.41505828499794006\n",
      "Epoch:7 , loss:0.3347119987010956\n",
      "Epoch:7 , loss:0.40134328603744507\n",
      "Epoch:7 , loss:0.5752764344215393\n",
      "Epoch:8 , loss:0.48541322350502014\n",
      "Epoch:8 , loss:0.30878475308418274\n",
      "Epoch:8 , loss:0.4448280930519104\n",
      "Epoch:8 , loss:0.4490109086036682\n",
      "Epoch:8 , loss:0.4608501195907593\n",
      "Epoch:8 , loss:0.40995481610298157\n",
      "Epoch:8 , loss:0.31197184324264526\n",
      "Epoch:8 , loss:0.41762620210647583\n",
      "Epoch:8 , loss:0.39055073261260986\n",
      "Epoch:8 , loss:0.31159478425979614\n",
      "Epoch:8 , loss:0.30611443519592285\n",
      "Epoch:8 , loss:0.28573593497276306\n",
      "Epoch:8 , loss:0.3586278259754181\n",
      "Epoch:9 , loss:0.4667542278766632\n",
      "Epoch:9 , loss:0.29647332429885864\n",
      "Epoch:9 , loss:0.3045208752155304\n",
      "Epoch:9 , loss:0.3024277091026306\n",
      "Epoch:9 , loss:0.33844950795173645\n",
      "Epoch:9 , loss:0.23479396104812622\n",
      "Epoch:9 , loss:0.2268223911523819\n",
      "Epoch:9 , loss:0.3601846992969513\n",
      "Epoch:9 , loss:0.2882005572319031\n",
      "Epoch:9 , loss:0.3556225597858429\n",
      "Epoch:9 , loss:0.27079880237579346\n",
      "Epoch:9 , loss:0.27287179231643677\n",
      "Epoch:9 , loss:0.5141308903694153\n",
      "Epoch:10 , loss:0.287752628326416\n",
      "Epoch:10 , loss:0.32805460691452026\n",
      "Epoch:10 , loss:0.25114020705223083\n",
      "Epoch:10 , loss:0.23290826380252838\n",
      "Epoch:10 , loss:0.22804638743400574\n",
      "Epoch:10 , loss:0.25670552253723145\n",
      "Epoch:10 , loss:0.2581561803817749\n",
      "Epoch:10 , loss:0.19254139065742493\n",
      "Epoch:10 , loss:0.415157288312912\n",
      "Epoch:10 , loss:0.26351431012153625\n",
      "Epoch:10 , loss:0.2569896876811981\n",
      "Epoch:10 , loss:0.28034284710884094\n",
      "Epoch:10 , loss:0.2544780969619751\n",
      "Epoch:11 , loss:0.2413458675146103\n",
      "Epoch:11 , loss:0.25146499276161194\n",
      "Epoch:11 , loss:0.19184066355228424\n",
      "Epoch:11 , loss:0.32870811223983765\n",
      "Epoch:11 , loss:0.22936469316482544\n",
      "Epoch:11 , loss:0.2533268630504608\n",
      "Epoch:11 , loss:0.1315787136554718\n",
      "Epoch:11 , loss:0.2760973274707794\n",
      "Epoch:11 , loss:0.20084933936595917\n",
      "Epoch:11 , loss:0.13127294182777405\n",
      "Epoch:11 , loss:0.3242630660533905\n",
      "Epoch:11 , loss:0.21538178622722626\n",
      "Epoch:11 , loss:0.37397128343582153\n",
      "Epoch:12 , loss:0.19347059726715088\n",
      "Epoch:12 , loss:0.14527414739131927\n",
      "Epoch:12 , loss:0.2208108901977539\n",
      "Epoch:12 , loss:0.1953830122947693\n",
      "Epoch:12 , loss:0.20050227642059326\n",
      "Epoch:12 , loss:0.18306614458560944\n",
      "Epoch:12 , loss:0.18758569657802582\n",
      "Epoch:12 , loss:0.2984432876110077\n",
      "Epoch:12 , loss:0.24055138230323792\n",
      "Epoch:12 , loss:0.19997049868106842\n",
      "Epoch:12 , loss:0.23612114787101746\n",
      "Epoch:12 , loss:0.1859295815229416\n",
      "Epoch:12 , loss:0.29070279002189636\n",
      "Epoch:13 , loss:0.14107933640480042\n",
      "Epoch:13 , loss:0.16275309026241302\n",
      "Epoch:13 , loss:0.1464657187461853\n",
      "Epoch:13 , loss:0.2684302031993866\n",
      "Epoch:13 , loss:0.22034405171871185\n",
      "Epoch:13 , loss:0.21907904744148254\n",
      "Epoch:13 , loss:0.1639697104692459\n",
      "Epoch:13 , loss:0.1540992259979248\n",
      "Epoch:13 , loss:0.20980599522590637\n",
      "Epoch:13 , loss:0.21358487010002136\n",
      "Epoch:13 , loss:0.16464607417583466\n",
      "Epoch:13 , loss:0.16535255312919617\n",
      "Epoch:13 , loss:0.26500827074050903\n",
      "Epoch:14 , loss:0.09911462664604187\n",
      "Epoch:14 , loss:0.15310491621494293\n",
      "Epoch:14 , loss:0.15400931239128113\n",
      "Epoch:14 , loss:0.1943838745355606\n",
      "Epoch:14 , loss:0.1808861494064331\n",
      "Epoch:14 , loss:0.12352407723665237\n",
      "Epoch:14 , loss:0.25604352355003357\n",
      "Epoch:14 , loss:0.24972350895404816\n",
      "Epoch:14 , loss:0.3168199062347412\n",
      "Epoch:14 , loss:0.1606808304786682\n",
      "Epoch:14 , loss:0.09913411736488342\n",
      "Epoch:14 , loss:0.1032944768667221\n",
      "Epoch:14 , loss:0.11974773555994034\n",
      "Epoch:15 , loss:0.12585343420505524\n",
      "Epoch:15 , loss:0.12100847065448761\n",
      "Epoch:15 , loss:0.21076653897762299\n",
      "Epoch:15 , loss:0.19610552489757538\n",
      "Epoch:15 , loss:0.17075508832931519\n",
      "Epoch:15 , loss:0.14717473089694977\n",
      "Epoch:15 , loss:0.14672833681106567\n",
      "Epoch:15 , loss:0.15992631018161774\n",
      "Epoch:15 , loss:0.12749406695365906\n",
      "Epoch:15 , loss:0.17980535328388214\n",
      "Epoch:15 , loss:0.08068110793828964\n",
      "Epoch:15 , loss:0.2789420783519745\n",
      "Epoch:15 , loss:0.06961707025766373\n",
      "Epoch:16 , loss:0.11963722109794617\n",
      "Epoch:16 , loss:0.13983523845672607\n",
      "Epoch:16 , loss:0.1418931484222412\n",
      "Epoch:16 , loss:0.11902011185884476\n",
      "Epoch:16 , loss:0.3458319306373596\n",
      "Epoch:16 , loss:0.11523211002349854\n",
      "Epoch:16 , loss:0.15454933047294617\n",
      "Epoch:16 , loss:0.1169065535068512\n",
      "Epoch:16 , loss:0.1728440821170807\n",
      "Epoch:16 , loss:0.1431807577610016\n",
      "Epoch:16 , loss:0.06390157341957092\n",
      "Epoch:16 , loss:0.14075204730033875\n",
      "Epoch:16 , loss:0.14588800072669983\n",
      "Epoch:17 , loss:0.13315366208553314\n",
      "Epoch:17 , loss:0.09455882012844086\n",
      "Epoch:17 , loss:0.08221859484910965\n",
      "Epoch:17 , loss:0.21472248435020447\n",
      "Epoch:17 , loss:0.21438990533351898\n",
      "Epoch:17 , loss:0.11456459015607834\n",
      "Epoch:17 , loss:0.10998749732971191\n",
      "Epoch:17 , loss:0.19697856903076172\n",
      "Epoch:17 , loss:0.09037163108587265\n",
      "Epoch:17 , loss:0.13025620579719543\n",
      "Epoch:17 , loss:0.10692010074853897\n",
      "Epoch:17 , loss:0.11699443310499191\n",
      "Epoch:17 , loss:0.2157554179430008\n",
      "Epoch:18 , loss:0.11774061620235443\n",
      "Epoch:18 , loss:0.12024948745965958\n",
      "Epoch:18 , loss:0.13602633774280548\n",
      "Epoch:18 , loss:0.1437970995903015\n",
      "Epoch:18 , loss:0.15731629729270935\n",
      "Epoch:18 , loss:0.1384163647890091\n",
      "Epoch:18 , loss:0.09135077893733978\n",
      "Epoch:18 , loss:0.18669848144054413\n",
      "Epoch:18 , loss:0.09078695625066757\n",
      "Epoch:18 , loss:0.09495076537132263\n",
      "Epoch:18 , loss:0.11508584767580032\n",
      "Epoch:18 , loss:0.16927745938301086\n",
      "Epoch:18 , loss:0.06348882615566254\n",
      "Epoch:19 , loss:0.10085640847682953\n",
      "Epoch:19 , loss:0.07054038345813751\n",
      "Epoch:19 , loss:0.18132318556308746\n",
      "Epoch:19 , loss:0.12050449103116989\n",
      "Epoch:19 , loss:0.09479917585849762\n",
      "Epoch:19 , loss:0.09272872656583786\n",
      "Epoch:19 , loss:0.09679162502288818\n",
      "Epoch:19 , loss:0.09294848144054413\n",
      "Epoch:19 , loss:0.13785198330879211\n",
      "Epoch:19 , loss:0.15292894840240479\n",
      "Epoch:19 , loss:0.10623648017644882\n",
      "Epoch:19 , loss:0.12053650617599487\n",
      "Epoch:19 , loss:0.2672369182109833\n",
      "Epoch:20 , loss:0.16612444818019867\n",
      "Epoch:20 , loss:0.11023972183465958\n",
      "Epoch:20 , loss:0.12125248461961746\n",
      "Epoch:20 , loss:0.08621757477521896\n",
      "Epoch:20 , loss:0.07075578719377518\n",
      "Epoch:20 , loss:0.09987075626850128\n",
      "Epoch:20 , loss:0.11648228019475937\n",
      "Epoch:20 , loss:0.07240394502878189\n",
      "Epoch:20 , loss:0.15696381032466888\n",
      "Epoch:20 , loss:0.20394037663936615\n",
      "Epoch:20 , loss:0.11308159679174423\n",
      "Epoch:20 , loss:0.06058830767869949\n",
      "Epoch:20 , loss:0.058890484273433685\n",
      "Epoch:21 , loss:0.07105503231287003\n",
      "Epoch:21 , loss:0.0716942623257637\n",
      "Epoch:21 , loss:0.09420271217823029\n",
      "Epoch:21 , loss:0.11738412827253342\n",
      "Epoch:21 , loss:0.12592284381389618\n",
      "Epoch:21 , loss:0.13984639942646027\n",
      "Epoch:21 , loss:0.12483583390712738\n",
      "Epoch:21 , loss:0.08368441462516785\n",
      "Epoch:21 , loss:0.1536301076412201\n",
      "Epoch:21 , loss:0.1414937525987625\n",
      "Epoch:21 , loss:0.07703690230846405\n",
      "Epoch:21 , loss:0.11996594816446304\n",
      "Epoch:21 , loss:0.027644604444503784\n",
      "Epoch:22 , loss:0.0642656534910202\n",
      "Epoch:22 , loss:0.11404097080230713\n",
      "Epoch:22 , loss:0.07931661605834961\n",
      "Epoch:22 , loss:0.0887037068605423\n",
      "Epoch:22 , loss:0.0924108624458313\n",
      "Epoch:22 , loss:0.08241580426692963\n",
      "Epoch:22 , loss:0.09124365448951721\n",
      "Epoch:22 , loss:0.06277202069759369\n",
      "Epoch:22 , loss:0.11675040423870087\n",
      "Epoch:22 , loss:0.07793433219194412\n",
      "Epoch:22 , loss:0.14123068749904633\n",
      "Epoch:22 , loss:0.18105155229568481\n",
      "Epoch:22 , loss:0.16295276582241058\n",
      "Epoch:23 , loss:0.13775238394737244\n",
      "Epoch:23 , loss:0.09969335049390793\n",
      "Epoch:23 , loss:0.11868460476398468\n",
      "Epoch:23 , loss:0.07553806155920029\n",
      "Epoch:23 , loss:0.058412328362464905\n",
      "Epoch:23 , loss:0.11575675755739212\n",
      "Epoch:23 , loss:0.14621026813983917\n",
      "Epoch:23 , loss:0.05189996957778931\n",
      "Epoch:23 , loss:0.06912393867969513\n",
      "Epoch:23 , loss:0.06698920577764511\n",
      "Epoch:23 , loss:0.0675361230969429\n",
      "Epoch:23 , loss:0.10646570473909378\n",
      "Epoch:23 , loss:0.18646952509880066\n",
      "Epoch:24 , loss:0.09920357912778854\n",
      "Epoch:24 , loss:0.09057947248220444\n",
      "Epoch:24 , loss:0.07516205310821533\n",
      "Epoch:24 , loss:0.060066286474466324\n",
      "Epoch:24 , loss:0.0851147323846817\n",
      "Epoch:24 , loss:0.04299230873584747\n",
      "Epoch:24 , loss:0.11387766897678375\n",
      "Epoch:24 , loss:0.10028820484876633\n",
      "Epoch:24 , loss:0.11463375389575958\n",
      "Epoch:24 , loss:0.1511792540550232\n",
      "Epoch:24 , loss:0.1299181431531906\n",
      "Epoch:24 , loss:0.06290259212255478\n",
      "Epoch:24 , loss:0.03477737307548523\n",
      "Epoch:25 , loss:0.07361146062612534\n",
      "Epoch:25 , loss:0.09252987056970596\n",
      "Epoch:25 , loss:0.06258795410394669\n",
      "Epoch:25 , loss:0.09986057877540588\n",
      "Epoch:25 , loss:0.06690679490566254\n",
      "Epoch:25 , loss:0.05840463563799858\n",
      "Epoch:25 , loss:0.11513885855674744\n",
      "Epoch:25 , loss:0.14190292358398438\n",
      "Epoch:25 , loss:0.06724798679351807\n",
      "Epoch:25 , loss:0.08169161528348923\n",
      "Epoch:25 , loss:0.04512724280357361\n",
      "Epoch:25 , loss:0.09182150661945343\n",
      "Epoch:25 , loss:0.22194544970989227\n",
      "Epoch:26 , loss:0.10415191948413849\n",
      "Epoch:26 , loss:0.06052127480506897\n",
      "Epoch:26 , loss:0.07853315770626068\n",
      "Epoch:26 , loss:0.06661276519298553\n",
      "Epoch:26 , loss:0.05892542004585266\n",
      "Epoch:26 , loss:0.06085463613271713\n",
      "Epoch:26 , loss:0.05483655259013176\n",
      "Epoch:26 , loss:0.11749065667390823\n",
      "Epoch:26 , loss:0.053992610424757004\n",
      "Epoch:26 , loss:0.17576700448989868\n",
      "Epoch:26 , loss:0.08375491946935654\n",
      "Epoch:26 , loss:0.08636670559644699\n",
      "Epoch:26 , loss:0.11798115074634552\n",
      "Epoch:27 , loss:0.10800645500421524\n",
      "Epoch:27 , loss:0.0696987584233284\n",
      "Epoch:27 , loss:0.06697802245616913\n",
      "Epoch:27 , loss:0.11216050386428833\n",
      "Epoch:27 , loss:0.06064301356673241\n",
      "Epoch:27 , loss:0.11503618955612183\n",
      "Epoch:27 , loss:0.08606073260307312\n",
      "Epoch:27 , loss:0.0624253936111927\n",
      "Epoch:27 , loss:0.06331304460763931\n",
      "Epoch:27 , loss:0.09349393844604492\n",
      "Epoch:27 , loss:0.06093345582485199\n",
      "Epoch:27 , loss:0.06946294754743576\n",
      "Epoch:27 , loss:0.06175679340958595\n",
      "Epoch:28 , loss:0.14446549117565155\n",
      "Epoch:28 , loss:0.06734240055084229\n",
      "Epoch:28 , loss:0.13143981993198395\n",
      "Epoch:28 , loss:0.07915420830249786\n",
      "Epoch:28 , loss:0.05438379570841789\n",
      "Epoch:28 , loss:0.06265917420387268\n",
      "Epoch:28 , loss:0.0833975076675415\n",
      "Epoch:28 , loss:0.058431074023246765\n",
      "Epoch:28 , loss:0.052660420536994934\n",
      "Epoch:28 , loss:0.038397710770368576\n",
      "Epoch:28 , loss:0.09725308418273926\n",
      "Epoch:28 , loss:0.05160554498434067\n",
      "Epoch:28 , loss:0.07972683757543564\n",
      "Epoch:29 , loss:0.053054407238960266\n",
      "Epoch:29 , loss:0.06424541771411896\n",
      "Epoch:29 , loss:0.051725082099437714\n",
      "Epoch:29 , loss:0.08303005248308182\n",
      "Epoch:29 , loss:0.13866862654685974\n",
      "Epoch:29 , loss:0.05102141201496124\n",
      "Epoch:29 , loss:0.1447513848543167\n",
      "Epoch:29 , loss:0.03912275284528732\n",
      "Epoch:29 , loss:0.04854266718029976\n",
      "Epoch:29 , loss:0.05023666098713875\n",
      "Epoch:29 , loss:0.1286865621805191\n",
      "Epoch:29 , loss:0.0566825270652771\n",
      "Epoch:29 , loss:0.024217752739787102\n",
      "Epoch:30 , loss:0.06898963451385498\n",
      "Epoch:30 , loss:0.04841870069503784\n",
      "Epoch:30 , loss:0.0436546728014946\n",
      "Epoch:30 , loss:0.06157165765762329\n",
      "Epoch:30 , loss:0.057177599519491196\n",
      "Epoch:30 , loss:0.05287418141961098\n",
      "Epoch:30 , loss:0.03935788944363594\n",
      "Epoch:30 , loss:0.0454745814204216\n",
      "Epoch:30 , loss:0.0626642256975174\n",
      "Epoch:30 , loss:0.11276189982891083\n",
      "Epoch:30 , loss:0.06686421483755112\n",
      "Epoch:30 , loss:0.17915470898151398\n",
      "Epoch:30 , loss:0.11135230958461761\n",
      "Epoch:31 , loss:0.05981665104627609\n",
      "Epoch:31 , loss:0.06119125708937645\n",
      "Epoch:31 , loss:0.07842882722616196\n",
      "Epoch:31 , loss:0.04458729922771454\n",
      "Epoch:31 , loss:0.060420140624046326\n",
      "Epoch:31 , loss:0.03057302162051201\n",
      "Epoch:31 , loss:0.06065536290407181\n",
      "Epoch:31 , loss:0.05645707994699478\n",
      "Epoch:31 , loss:0.10135184973478317\n",
      "Epoch:31 , loss:0.13232393562793732\n",
      "Epoch:31 , loss:0.04704240337014198\n",
      "Epoch:31 , loss:0.04531002789735794\n",
      "Epoch:31 , loss:0.1680108606815338\n",
      "Epoch:32 , loss:0.054902635514736176\n",
      "Epoch:32 , loss:0.12575459480285645\n",
      "Epoch:32 , loss:0.04482526332139969\n",
      "Epoch:32 , loss:0.05578257516026497\n",
      "Epoch:32 , loss:0.05531952902674675\n",
      "Epoch:32 , loss:0.10717422515153885\n",
      "Epoch:32 , loss:0.07599815726280212\n",
      "Epoch:32 , loss:0.04807814210653305\n",
      "Epoch:32 , loss:0.08513828366994858\n",
      "Epoch:32 , loss:0.05238239839673042\n",
      "Epoch:32 , loss:0.04402514547109604\n",
      "Epoch:32 , loss:0.056533657014369965\n",
      "Epoch:32 , loss:0.03230506554245949\n",
      "Epoch:33 , loss:0.15231241285800934\n",
      "Epoch:33 , loss:0.09147472679615021\n",
      "Epoch:33 , loss:0.04820045828819275\n",
      "Epoch:33 , loss:0.05045647174119949\n",
      "Epoch:33 , loss:0.049182113260030746\n",
      "Epoch:33 , loss:0.04212426021695137\n",
      "Epoch:33 , loss:0.08585803210735321\n",
      "Epoch:33 , loss:0.06112721562385559\n",
      "Epoch:33 , loss:0.04749574139714241\n",
      "Epoch:33 , loss:0.06406065076589584\n",
      "Epoch:33 , loss:0.037020593881607056\n",
      "Epoch:33 , loss:0.04970250651240349\n",
      "Epoch:33 , loss:0.028867224231362343\n",
      "Epoch:34 , loss:0.10379847139120102\n",
      "Epoch:34 , loss:0.07241492718458176\n",
      "Epoch:34 , loss:0.05158447101712227\n",
      "Epoch:34 , loss:0.06844085454940796\n",
      "Epoch:34 , loss:0.04089144617319107\n",
      "Epoch:34 , loss:0.04235394299030304\n",
      "Epoch:34 , loss:0.04309191182255745\n",
      "Epoch:34 , loss:0.05644134059548378\n",
      "Epoch:34 , loss:0.05359873175621033\n",
      "Epoch:34 , loss:0.0518314503133297\n",
      "Epoch:34 , loss:0.04953404515981674\n",
      "Epoch:34 , loss:0.09702389687299728\n",
      "Epoch:34 , loss:0.06438443809747696\n",
      "Epoch:35 , loss:0.04822202026844025\n",
      "Epoch:35 , loss:0.04670415446162224\n",
      "Epoch:35 , loss:0.04996056854724884\n",
      "Epoch:35 , loss:0.03620188310742378\n",
      "Epoch:35 , loss:0.0489632785320282\n",
      "Epoch:35 , loss:0.05436499044299126\n",
      "Epoch:35 , loss:0.04721565172076225\n",
      "Epoch:35 , loss:0.13113652169704437\n",
      "Epoch:35 , loss:0.042555369436740875\n",
      "Epoch:35 , loss:0.12182588130235672\n",
      "Epoch:35 , loss:0.0338488444685936\n",
      "Epoch:35 , loss:0.06413625180721283\n",
      "Epoch:35 , loss:0.033735401928424835\n",
      "Epoch:36 , loss:0.12783919274806976\n",
      "Epoch:36 , loss:0.05929218977689743\n",
      "Epoch:36 , loss:0.05527162924408913\n",
      "Epoch:36 , loss:0.060480136424303055\n",
      "Epoch:36 , loss:0.04267338663339615\n",
      "Epoch:36 , loss:0.034740664064884186\n",
      "Epoch:36 , loss:0.043280333280563354\n",
      "Epoch:36 , loss:0.047219857573509216\n",
      "Epoch:36 , loss:0.04846537113189697\n",
      "Epoch:36 , loss:0.08410760760307312\n",
      "Epoch:36 , loss:0.0424417182803154\n",
      "Epoch:36 , loss:0.04140796512365341\n",
      "Epoch:36 , loss:0.049156662076711655\n",
      "Epoch:37 , loss:0.0866365060210228\n",
      "Epoch:37 , loss:0.03605877235531807\n",
      "Epoch:37 , loss:0.0316389761865139\n",
      "Epoch:37 , loss:0.03953240439295769\n",
      "Epoch:37 , loss:0.08515864610671997\n",
      "Epoch:37 , loss:0.05974365025758743\n",
      "Epoch:37 , loss:0.028965042904019356\n",
      "Epoch:37 , loss:0.10888854414224625\n",
      "Epoch:37 , loss:0.06588409841060638\n",
      "Epoch:37 , loss:0.04035856947302818\n",
      "Epoch:37 , loss:0.041660722345113754\n",
      "Epoch:37 , loss:0.0395626462996006\n",
      "Epoch:37 , loss:0.03618977218866348\n",
      "Epoch:38 , loss:0.033402055501937866\n",
      "Epoch:38 , loss:0.05754174664616585\n",
      "Epoch:38 , loss:0.02730827033519745\n",
      "Epoch:38 , loss:0.04464299976825714\n",
      "Epoch:38 , loss:0.04615340754389763\n",
      "Epoch:38 , loss:0.04799798130989075\n",
      "Epoch:38 , loss:0.14616520702838898\n",
      "Epoch:38 , loss:0.03303464874625206\n",
      "Epoch:38 , loss:0.03796001523733139\n",
      "Epoch:38 , loss:0.07342607527971268\n",
      "Epoch:38 , loss:0.0731603130698204\n",
      "Epoch:38 , loss:0.03505368530750275\n",
      "Epoch:38 , loss:0.03740677982568741\n",
      "Epoch:39 , loss:0.07830565422773361\n",
      "Epoch:39 , loss:0.03897877782583237\n",
      "Epoch:39 , loss:0.09933868795633316\n",
      "Epoch:39 , loss:0.03438444063067436\n",
      "Epoch:39 , loss:0.03759145364165306\n",
      "Epoch:39 , loss:0.06332869082689285\n",
      "Epoch:39 , loss:0.0371360220015049\n",
      "Epoch:39 , loss:0.030188744887709618\n",
      "Epoch:39 , loss:0.021984802559018135\n",
      "Epoch:39 , loss:0.027642343193292618\n",
      "Epoch:39 , loss:0.033930860459804535\n",
      "Epoch:39 , loss:0.11930452287197113\n",
      "Epoch:39 , loss:0.039185427129268646\n",
      "Epoch:40 , loss:0.033272065222263336\n",
      "Epoch:40 , loss:0.033497244119644165\n",
      "Epoch:40 , loss:0.027408702298998833\n",
      "Epoch:40 , loss:0.10738880932331085\n",
      "Epoch:40 , loss:0.05738845840096474\n",
      "Epoch:40 , loss:0.0670449361205101\n",
      "Epoch:40 , loss:0.042046934366226196\n",
      "Epoch:40 , loss:0.048096444457769394\n",
      "Epoch:40 , loss:0.043179403990507126\n",
      "Epoch:40 , loss:0.0386166125535965\n",
      "Epoch:40 , loss:0.041270267218351364\n",
      "Epoch:40 , loss:0.06501296162605286\n",
      "Epoch:40 , loss:0.05317271873354912\n",
      "Epoch:41 , loss:0.046442776918411255\n",
      "Epoch:41 , loss:0.08168482780456543\n",
      "Epoch:41 , loss:0.03161419555544853\n",
      "Epoch:41 , loss:0.02816883474588394\n",
      "Epoch:41 , loss:0.025217130780220032\n",
      "Epoch:41 , loss:0.030566051602363586\n",
      "Epoch:41 , loss:0.029251515865325928\n",
      "Epoch:41 , loss:0.06140581890940666\n",
      "Epoch:41 , loss:0.03929831460118294\n",
      "Epoch:41 , loss:0.09168320149183273\n",
      "Epoch:41 , loss:0.05971891060471535\n",
      "Epoch:41 , loss:0.035521771758794785\n",
      "Epoch:41 , loss:0.10322494059801102\n",
      "Epoch:42 , loss:0.035990193486213684\n",
      "Epoch:42 , loss:0.08290740102529526\n",
      "Epoch:42 , loss:0.0409737303853035\n",
      "Epoch:42 , loss:0.04487895593047142\n",
      "Epoch:42 , loss:0.059786662459373474\n",
      "Epoch:42 , loss:0.02886981889605522\n",
      "Epoch:42 , loss:0.03723916783928871\n",
      "Epoch:42 , loss:0.02906840294599533\n",
      "Epoch:42 , loss:0.054740507155656815\n",
      "Epoch:42 , loss:0.03449995070695877\n",
      "Epoch:42 , loss:0.10319715738296509\n",
      "Epoch:42 , loss:0.025986509397625923\n",
      "Epoch:42 , loss:0.029547514393925667\n",
      "Epoch:43 , loss:0.06515056639909744\n",
      "Epoch:43 , loss:0.024419818073511124\n",
      "Epoch:43 , loss:0.0365070179104805\n",
      "Epoch:43 , loss:0.03260662779211998\n",
      "Epoch:43 , loss:0.045603249222040176\n",
      "Epoch:43 , loss:0.023599525913596153\n",
      "Epoch:43 , loss:0.031249456107616425\n",
      "Epoch:43 , loss:0.06631531566381454\n",
      "Epoch:43 , loss:0.02679656632244587\n",
      "Epoch:43 , loss:0.08018374443054199\n",
      "Epoch:43 , loss:0.08410020172595978\n",
      "Epoch:43 , loss:0.059119388461112976\n",
      "Epoch:43 , loss:0.018665820360183716\n",
      "Epoch:44 , loss:0.029322661459445953\n",
      "Epoch:44 , loss:0.06245789676904678\n",
      "Epoch:44 , loss:0.035001564770936966\n",
      "Epoch:44 , loss:0.03960894048213959\n",
      "Epoch:44 , loss:0.02638942562043667\n",
      "Epoch:44 , loss:0.023857317864894867\n",
      "Epoch:44 , loss:0.09894831478595734\n",
      "Epoch:44 , loss:0.05177779123187065\n",
      "Epoch:44 , loss:0.03469153121113777\n",
      "Epoch:44 , loss:0.042511239647865295\n",
      "Epoch:44 , loss:0.037293337285518646\n",
      "Epoch:44 , loss:0.06030138209462166\n",
      "Epoch:44 , loss:0.03852952644228935\n",
      "Epoch:45 , loss:0.05080191791057587\n",
      "Epoch:45 , loss:0.0633123442530632\n",
      "Epoch:45 , loss:0.03404980152845383\n",
      "Epoch:45 , loss:0.06520203500986099\n",
      "Epoch:45 , loss:0.039311788976192474\n",
      "Epoch:45 , loss:0.022333268076181412\n",
      "Epoch:45 , loss:0.061860810965299606\n",
      "Epoch:45 , loss:0.06382223218679428\n",
      "Epoch:45 , loss:0.029849160462617874\n",
      "Epoch:45 , loss:0.033298082649707794\n",
      "Epoch:45 , loss:0.033609069883823395\n",
      "Epoch:45 , loss:0.03476029634475708\n",
      "Epoch:45 , loss:0.025896480306982994\n",
      "Epoch:46 , loss:0.028999971225857735\n",
      "Epoch:46 , loss:0.033613551408052444\n",
      "Epoch:46 , loss:0.02752656489610672\n",
      "Epoch:46 , loss:0.03953688219189644\n",
      "Epoch:46 , loss:0.07400787621736526\n",
      "Epoch:46 , loss:0.04775403439998627\n",
      "Epoch:46 , loss:0.02767055109143257\n",
      "Epoch:46 , loss:0.022945495322346687\n",
      "Epoch:46 , loss:0.017805688083171844\n",
      "Epoch:46 , loss:0.028528619557619095\n",
      "Epoch:46 , loss:0.07488474249839783\n",
      "Epoch:46 , loss:0.06269960850477219\n",
      "Epoch:46 , loss:0.09758559614419937\n",
      "Epoch:47 , loss:0.030456718057394028\n",
      "Epoch:47 , loss:0.02331160008907318\n",
      "Epoch:47 , loss:0.03857234865427017\n",
      "Epoch:47 , loss:0.02867876924574375\n",
      "Epoch:47 , loss:0.08606985211372375\n",
      "Epoch:47 , loss:0.09038165956735611\n",
      "Epoch:47 , loss:0.028237052261829376\n",
      "Epoch:47 , loss:0.02780061401426792\n",
      "Epoch:47 , loss:0.05346633866429329\n",
      "Epoch:47 , loss:0.03977592661976814\n",
      "Epoch:47 , loss:0.023542804643511772\n",
      "Epoch:47 , loss:0.03896472603082657\n",
      "Epoch:47 , loss:0.02999495342373848\n",
      "Epoch:48 , loss:0.022253625094890594\n",
      "Epoch:48 , loss:0.02808202989399433\n",
      "Epoch:48 , loss:0.019469574093818665\n",
      "Epoch:48 , loss:0.031309399753808975\n",
      "Epoch:48 , loss:0.03232010453939438\n",
      "Epoch:48 , loss:0.02393399365246296\n",
      "Epoch:48 , loss:0.04398103803396225\n",
      "Epoch:48 , loss:0.06141684949398041\n",
      "Epoch:48 , loss:0.06124044954776764\n",
      "Epoch:48 , loss:0.03459099307656288\n",
      "Epoch:48 , loss:0.03406751528382301\n",
      "Epoch:48 , loss:0.025944191962480545\n",
      "Epoch:48 , loss:0.2081337422132492\n",
      "Epoch:49 , loss:0.02764328569173813\n",
      "Epoch:49 , loss:0.07946500182151794\n",
      "Epoch:49 , loss:0.07862673699855804\n",
      "Epoch:49 , loss:0.034373871982097626\n",
      "Epoch:49 , loss:0.04391741007566452\n",
      "Epoch:49 , loss:0.023297781124711037\n",
      "Epoch:49 , loss:0.027428459376096725\n",
      "Epoch:49 , loss:0.024146098643541336\n",
      "Epoch:49 , loss:0.032585177570581436\n",
      "Epoch:49 , loss:0.07255017012357712\n",
      "Epoch:49 , loss:0.05047052353620529\n",
      "Epoch:49 , loss:0.024135388433933258\n",
      "Epoch:49 , loss:0.021690962836146355\n",
      "Epoch:50 , loss:0.02180762216448784\n",
      "Epoch:50 , loss:0.03332800418138504\n",
      "Epoch:50 , loss:0.05105097219347954\n",
      "Epoch:50 , loss:0.02970137447118759\n",
      "Epoch:50 , loss:0.020087048411369324\n",
      "Epoch:50 , loss:0.035795845091342926\n",
      "Epoch:50 , loss:0.03888118267059326\n",
      "Epoch:50 , loss:0.03219382464885712\n",
      "Epoch:50 , loss:0.06252399832010269\n",
      "Epoch:50 , loss:0.05434861779212952\n",
      "Epoch:50 , loss:0.030498409643769264\n",
      "Epoch:50 , loss:0.027067407965660095\n",
      "Epoch:50 , loss:0.10798252373933792\n"
     ]
    }
   ],
   "source": [
    "model=MyModel(X_train_tensor.shape[1])\n",
    "#optimizer\n",
    "\n",
    "optim=torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "for epochs in range(epochs):\n",
    "\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "\n",
    "        y_pred=model(batch_features)\n",
    "\n",
    "        loss=loss_func(y_pred,batch_labels.view(-1,1))\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step() #updating parameters\n",
    "\n",
    "        print(f'Epoch:{epochs+1} , loss:{loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f7e3b310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 30])\n"
     ]
    }
   ],
   "source": [
    "print(batch_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9405ef17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9740\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "accuracy_list=[]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_features,batch_labels in test_loader:\n",
    "\n",
    "        y_pred=model.forward(batch_features)\n",
    "        y_pred=(y_pred>0.5).float()\n",
    "\n",
    "        batch_accuracy=(y_pred.view(-1)==batch_labels).float().mean().item()\n",
    "        accuracy_list.append(batch_accuracy)\n",
    "\n",
    "overall_accuracy=sum(accuracy_list)/len(accuracy_list)\n",
    "print(f'Accuracy:{overall_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422c9c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
